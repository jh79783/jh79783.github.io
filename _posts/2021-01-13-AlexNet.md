---
layout: post
title: AlexNet
data: 2021-01-13
excerpt: "AlexNet"
tags: [AlexNet, network]
coments: false
mathjax: true
---

# AlexNet

ILSVRC-2010에서 1000개의 클래스로 분류하는 CNN을 학습시켜 top1, top5 에러율이 37.5%, 17.0%를 기록하였습니다. 또한 ILSVRC-2012에서는 top-5 에러율을 15.3%를 기록하여 우승하였습니다.

이때 5개의 convolutional layer와 3개의 fully-connected layer를 사용해 클래스를 분류하였으며 2개의 GTX 580 3GB GPU를 사용하여 5\~6일이 걸렸다고 합니다.

## ReLU

AlexNet에서는 활성화 함수로 ReLU를 사용하였습니다.

전에는 일반적으로 sigmoid나 tanh함수를 사용하였는데, 이들은 saturating(gradient vanishing)의 문제가 있었으며, 속도가 상당히 느렸습니다.

따라서 non-saturaing한 ReLU를 사용하였고, 이를 통해 더 빠른 학습이 가능해졌습니다.

## Multiple GPUs

AlexNet에서는 GTX 580 3GB GPU를 두개 사용하여 학습하였습니다.

현재 GPU는 시스템 메모리를 거치지 않고 서로 메모리에 직접 접근할 수 있기 때문에 GPU 병렬에 적합하다고 설명하고 있습니다.

또한 각 GPU에 뉴런의 절반을 배치 하고 추가적인 트릭을 사용하였습니다. 3번째 layer를 보면 모든 맵에서 입력을 받고있습니다. 하지만 4번째 layer에서는 동일한 GPU에 있는 3번째 맵에서만 입력을 받습니다. 논문에서는 이를 통해 통신량을 정확하게 조정할 수 있다고 설명하고 있습니다.

## Local Response Normalization

neuron의 ouput을 주변값과 평균내는 것입니다.

논문에서는 normalization이 generalization에 도움이 된다고 하였습니다.



데이터의 overfitting을 줄이기 위해 AlexNet에서는 data augmentation과 dropout을 사용했습니다.

## Data Augmentation

데이터 세트의 다양성을 위해 인위적으로 원본 이미지에 변형을 주어 사용하였습니다.

두 가지 다른 형태의 데이터를 사용합니다. 두 가지 모두 매우 작은 연산이 필요하기 때문에 이미지를 디스크에 저장 할 필요가 없을 뿐더러 cpu를 통해 생성됩니다.

첫번째로는 원본 이미지(256\*256)를 translation 및 horizontal reflection을 적용하여 224\*224크기의 patch를 추출합니다. 이는 4개의 coner patch와 한개의 center patch가 추출되며 이를 수평반사시켜 총 10개의 patch를 추출합니다.

두번째로 train 이미지에서 RGB 채널의 강도를 변경하는 것입니다. 이를 통해 물체의  정체성이 조명의 강도, 색상의 변화에 따라 변화하지 않는 것을 포착할 수 있습니다.

따라서 데이터의 양을 늘리게 됩니다.

## Dropout

dropout은 학습 시 노드간의 연결을 확률을 통해 연산에 포함시키지 않는 것입니다.

매 학습마다 다양한 연결이 생성되어 overfitting을 방지하는데 도움이 됩니다. 논문에서는 dropout을 0.5로 설정하여 overfitting을 방지하였습니다.

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/alexnet/AlexNet_architecture.jpg?raw=true)

- 첫번째 convolution layer : filter의 크기는 11\*11\*3이고, 96개가 존재하며 stride는 4를 적용하여 55\*55\*96의 feature map이 생성됩니다. 이를 ReLU함수를 통과 후 3\*3 크기의 stride가 2로 설정된 overlapping max pooling을 사용합니다. 이 결과 27\*27\*96의 feature map이 생성됩니다. 그 후 local respponse normalization을 수행하는데, 이때 특성맵의 크기는 변하지 않고 유지됩니다.
- 두번째 convolution layer: 5\*5\*48 크기의 filter이 256개 있으며 stride는 1로, zero-padding을 2로 설정하여 27\*27\*256의 feature map이 생성됩니다. 위와 같은 max pooling을 사용해 최종적으로 13\*13\*256의 feature map이 출력됩니다.
- 세번째 convolution layer: 3\*3\*256크기의 filter을 384개 사용하고, stirde와 zero-padding을 각각 1로 설정하여 13\*13\*384의 feature map이 생성됩니다.
- 네번째 convolution layer: 3\*3\*192크기의 filter를 384개 사용, stride와 zero-padding은 세번째 layer와 동등하게 1로 설정해 주어 13\*13\*384 크기의 feature map이 생성됩니다.
- 다섯번째 convolution layer: 3\*3\*192 크기의 filter를 256개 사용하고, 위의 layer와 같이 1로 설정합니다. 따라서 13\*13\*256크기의 feature map이 생성됩니다. 여기에 3\*3크기의 stride는2인 max pooling을 적용해 6\*6\*256의 feature map을 얻게 됩니다.
- 여섯번째 fully connected layer: 6\*6\*256의 feature map을 펼쳐주어 9216차원의 벡터로 만듭니다. 이것을 4096개의 뉴런과 연결해 줍니다.
- 일곱번째 fully connected layer: 이 layer도 4096개의 뉴런으로 이루어져 있으며 연결되어 있습니다. 
- 여덟번째 fully connected layer: 1000개의 뉴런으로 구성되어 있습니다. 이 layer의 출력값에 softmax를 적용해 1000개의 클래스에 속할 확률를 나타내게 됩니다.