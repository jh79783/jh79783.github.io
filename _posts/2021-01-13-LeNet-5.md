---
layout: post
title: LeNet-5
data: 2021-01-13
excerpt: "LeNet"
tags: [LeNet, network]
coments: false
mathjax: true
---

# LeNet-5(1998)

LeNet은 CNN을 처음으로 제안한 논문으로 Image Classfication에 보편적으로 사용되고 있습니다.

이때의 classifier로 사용되던건 fully-connected neural network인데, 이것이 갖고있는 한계를 개선하기 위한 것이 목적이였습니다.

fully-connected는 parameter가 기하급수적으로 많아지고 데이터의 공간적인 위상(topology)이 무시되며 목표로하는 성능을 내기위한 엄청난 양의 학습 데이터가 필요하는 등 다양한 문제점이 있었습니다.  따라서 이를 개선하고자 Local receptive field, Shared weight, Sub-sampling가 결합한  Convolutional Neural network(CNN)를 개발하게 되었습니다.

local receptive filed는 뉴런이 반응하는 것에서 아이디어를 얻어 특정 영역에서의 특징을 추출하도록 한것입니다. 이런 과정을 convolution이라고 하고, 여기서의 filter는 하나의 weight가 됩니다. 

weight값을 학습하여 계속해서 업데이트를 진행하며, 이것이 끝나면 feature map(filter가 적용되어 input으로부터 검출된 receptive field의 집합)을 얻게됩니다. filter를 통해 다음 layer를 local하게 구성하여 weight의 수도 줄어들게 되었습니다.

shared weight는 filter를 적용하여 나타난 결과는 계속 변하지만 적용하는 filter는 변하지 않는것을 말합니다. 즉, 동일한 weight가 convoultion을 진행할 때 input에 대해서 동일하게 적용(shared)되는 것을 말합니다.

sub-sampling은 추출한 local feature로 부터 input의 translation, distortion에 관게없이 위상(topology)에 영향을 받지않는 global feature를 추출하기 위한 것입니다. 

> local feature : 객체인식, 식별. 즉, 사람인지 동물인지, 사물인지 인식하는 것
>
> global feature : 영상에서 어떤 물체가 존재하는지 찾는 것

이 모든 과정을 거친 후 classification을 진행하게 됩니다.

## LeNet-5 구조

![](.\LeNet-5_architecture.jpg)

LeNet-5의 architecture입니다.

> input - C1 - S2 - C3 - S4 - C5 - F6 - output

입력과 출력 부분을 제외한 총 6개의 레이어로 구성되어있으며, 입력은 32\*32입니다. 기존의 LeNet-1의 경우 28\*28의 사이즈를 사용하였다고 했는데, 이미지를 중앙에 위치하게 하고, 식별이 가능한 edge나 coner(갈라지는 부분, 곡선, 끝) 등이 이미지의 중앙의 receptive field에 위치 할 수도 있기 때문에 사이즈를 늘려 사용하였다고 합니다.

C는 convolutional layer, S는 sub-sampling layer, F는 fully-connected layer를 의미합니다.

- C1 layer

32\*32\*1크기의 input으로 부터 (5\*5\*6)의 filter를 통해 28\*28\*6의 feature map을 생성합니다.

패딩처리를 하지 않아 이미지의 크기가 줄어들었습니다.

- S2 layer

C1의 feature map로 부터 (2\*2\*6)의 filter를 통해 14\*14\*6크기의 feature map을 생성합니다. average pooling을 수행하여 weight와 bias가 각각 1개의 파라미터를 갖게 되며, weight와 bias가 추가된 결과에 sigmoid함수가 적용됩니다.

- C3 layer

(5\*5\*16)크기의 filter를 사용해 10\*10\*16의 featrue map을 생성합니다.

여기서 특이한 점은 S2 layer로부터 입력된 6개의 데이터로 16개의 데이터를 만드는데 테이블과 같이 선택적으로 연결 시켰습니다.

![](.\LeNet-5_table1.jpg)

이것을 통해 network의 대칭적인 성질을 제거할 수 있습니다. 따라서 convolution한 결과의 feature들이 다른 부분과 섞여 global feature를 얻기위함입니다.

- S4 layer

C3 layer로 부터 출력된 데이터를 input하여 (2\*2\*16)크기의 filter를 통해 5\*5\*16의 feature map을 생성합니다.

- C5 layer

(5\*5\*120)크기의 filter를 사용해 1\*1\*120의 feature map을 생성합니다.

- F6 layer

C5 layer의 출력물로부터(1\*1\*120) 1\*1\*84의 feature map을 생성합니다.

- outpu layer

최종적으로 10개의 class로 구분하게 되어 출력하게 됩니다.