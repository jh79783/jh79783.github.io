---
layout: post
title: SPACH(SPAtial and CHannel)
data: 2021-10-04
excerpt: "spach"
tags: [transformer, mlp, cnn]
coments: false
mathjax: true
---

# SPACH(SPAtial and CHannel)

- 제목: A Battle of Network Structures: An Empirical Study of CNN, Transformer, and MLP
- 저자: Yucheng Zhao 외 5명
- 학술지: arxiv 2021

## Introduction

- computer vision분야에서 CNN계열, transformer계열, MLP계열이 현재 경쟁하고 있는 상태이며, 어떤것이 vision에 더 적합한지, 우수한지 결론이 나지 않은 상태임

- 소개된 모델들의 성능이 측정된 환경이 논문마다 다르기 때문에 이들을 정확하게 비교하기 힘듬

  > VIT, MLP의 경우 최소 1400만 ~ 3억장에 이르는 dataset을 pre-train진행하였으며, 다른 CNN의 경우 deformable conv등 다양한 방법을 사용
  >
  > 현재는 다양한 기법, 파라미터 하나가 성능에 매우 민감한 역할을 함

- 소개된 모델들의 모델이 정해진 환경이아닌 너무 다른 환경에서 성능이 측정되어있기 때문에 이들을 정확하게 비교하기가 힘듬

- 따라서 본 논문에서는 세개의 모델을 같은환경에서 비교할 수 있도록 Unified Experimental Framework인 SPACH를 제안함

## A Unified Experimental Framework

![](C:\workspace\논문\SPACH\fig1.png)

- Spatial Mixing은 fig2와 같이 구성되어있음

![](C:\workspace\논문\SPACH\fig2.png)

> 실질적으로 모델에서 차이를 만들어내는 부분

- 구조는 fig1과 같이 매우 간단한 구조로 구성되어 있음

- VIT/MLP-Mixer와 비슷하게 전체 이미지에서 patch를 가져오게 되며, 그 후 patch embedding을 거쳐 N개의 Mixing Block을 진행하고, Global Avg. pooling후, linear classifier를 통해 최종 class가 출력됨

- 하나의 Mixing Block은 fig1의 (b)와 같은 구조로 되어있음

- token 사이의 연산을 위한 spatial Mixing과 하나의 token내부에서 연산이 되는 channel mixing을 수행하며(MLP-Mixer와 비슷)그 후 residual을 더해주어 output이 됨

- CNN의 경우 fig1의 (c)와 같이 multi stage에서 feature를 가져오는 것이 일반적인데, VIT/MLP-Mixer의 경우 single stage에서만 수행하였음

- 따라서 VIT/MLP-Mixer도 CNN과 같이 Multi stage에서 사용을 해보고자 함

- Single stage에서는 낮은 resolution(16\*16)으로 사용하였다고 볼 수 있으며, MS(Multi Stage)의 경우에는 이보다 큰 resolution(4\*4)을 사용하여 downsampling하였음

- 기본적으로 MS의 경우 4개의 stage를 사용하였으며 down sample ratio는 4, 8, 16, 32를 사용하였음

- 또한, MS에서는 고해상도 이미지를 사용하였기때문에 Transformer와 MLP에서 높은 computational cost가 요구됨. 따라서 MS에서 첫번째 단계의 Mixing Block에서는 conv만을 사용하여 구현하였음

  > 이러면 transformer와 MLP, conv 비교가 정확하지 않은것 같을듯...?

- SPACH는 세가지의 사이즈로 나누어 실험하였음

![](C:\workspace\논문\SPACH\table1.png)

## Mixing Block Design

- Mixing Block을 수식으로 표현하면 다음과 같음

$$
Y=F_s(F_c(X))
$$

> $F_s$: spatial mixing function
>
> $F_c$: channel mixing function

- convolution structure의 경우 3\*3 depth-wise conv를 사용함
- transformer의 경우 전통적인 absolute positional embedding(sin-cos embedding)이 image에 오히려 악영향을 끼친다는 결과가 있기때문에 convolutional positional encoding(CPE)를 사용함

> CPE: token을 convolution한 것을 positional embedding으로 사용하는 것
>
> 인접한 token끼리 convolution연산한 값이 나오게 됨

- original MLP-Mixer에서는 positional embedding을 사용하지 않았지만, 본 논문에서는 CPE를 사용하였음

## Empirical Studies on Mixing Blocks

- ImageNet-1K dataset을 사용하여 실험을 진행
- DeiT의 training setting을 거의 비슷하게 하여 training을 진행
- input resolution: 224\*224
- optimizer: AdamW
- epochs: 300
- GPU: use 8 GPU (P100)
- batch size: 128 per GPU

### Muti-Stage is Superior to Single-Stage

- Multi-Stage는 CNN에서는 일반적인 형태인데, 이를 transformer나 MLP에 적용하였더니 똑같이 성능이 더 뛰어난 것을 확인하였음
- 즉, Multi-Stage가 항상 성능이 더 뛰어남

![](C:\workspace\논문\SPACH\table3.png)

![](C:\workspace\논문\SPACH\fig3.png)

### Local Modeling is Crucial

- Local Modeling이라는 것은 3\*3 convolution(CPE)과 같은 것을 의미함
- spatial mixing에서 3\*3 depth-wise convolution(CPE)을 사용하였는데, 사용한 경우 성능이 더 좋아지는 것을 확인하였음

![](C:\workspace\논문\SPACH\table4.png)

> -가 첨부된 모델이 CPE가 빠진 모델인데, 이 경우 원본 모델의 방법을 사용함

- MLP의 경우 다른 모델에 비해 parameter의 수가 많은데, 이것이 saturation이 빨리 일어나게 하는 원인이라고 하였음

![](C:\workspace\논문\SPACH\fig4.png)

![](C:\workspace\논문\SPACH\table5.png)

- saturation을 늦추기 위해 본 논문에서는 두 가지 방법을 제안함

  1. MS 사용

  2. weight share

     > single stage의 경우 mixing block내에서 weight를 share하였으며
     >
     > multi stage의 경우 각 stage의 mixing block에서 weight를 share하였음

- 실험을 진행하며 Convolution과 Transformer는 서로 보완적인 관계에 있는 것을 확인하였음

  > convolution은 generalization하는데 좋으며 transformer는 큰 model capacity를 갖을 수 있음

![](C:\workspace\논문\SPACH\fig5.png)

## Hybrid Model

- convolution과 transformer를 서로 보완할 수 있는 점을 통해 두 가지를 결합한 Hybrid Model을 생성함

- 기본적으로 MS를 사용하였으며, 모델의 크기에 따라서 stage의 layer를 convolution + self attention으로 변경하였음

  >Hybrid-MS-XS: 3번째 stage의 layer(12 layer)에서 마지막으로부터의 10개의 layer를 transformer로 변경, 4번째 stage의 마지막으로부터의 2개의 layer를 transformer로 변경함

![](C:\workspace\논문\SPACH\table6.png)