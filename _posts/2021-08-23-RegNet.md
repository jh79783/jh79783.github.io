---
layout: post
title: RegNet
data: 2021-08-23
excerpt: "RegNet"
tags: [cnn, network]
coments: false
mathjax: true
---

# RegNet

- 제목: Designing Network Design Sapces
- 저자: Ilija Radosavovic, Raj Prateek Kosaraju, Ross Grishick, Kaiming He, Piotr Dollar
- 인용수: 201회
- 학술지: CVPR 2020

## Introduction

- LeNet, AlexNet, VGG, ResNet은 효과적으로 잘 알려진 네트워크 디자인임

- 이 네트워크들을 통하여 convolution, network와 data의 크기, depth, residual의 중요성을 알려주었으며, 이들을 네트워크를 디자인하는데에 있어 하나의 원칙으로 사용

- 본 논문은 다양한 네트워크에 적용이 가능한 general design principle을 생성하는 것을 목표로 함

- 이렇게 네트워크를 직접 설계하는 것이 큰 발전을 이끌어 왔지만, 네트워크 디자인의 선택 폭이 넓어지면서 잘 최적화된 네트워크를 수동으로 찾는것이 어려워짐

- 이에따라 NAS(neural architectur search)를 사용하여 고정된 search space에서 자동으로 좋은 네트워크를 찾아줌

- 하지만, NAS는 특정 설계에서의 단일 네트워크를 찾아주며, 구조를 사람이 이해하기 어려움

  > 여러곳에서 범용적으로 사용하기가 힘듬

- 따라서 본 논문에서는 수동 디자인과 NAS의 장점을 조합한 새로운 네트워크 디자인 paradigm을 제시함

- 새로운 paradigm은 개별 네트워크 인스턴스를 디자인하는 것에 집중하는 것이 아닌 여러 네트워크에 적용 될 수 있는 design space를 디자인 하는 것

- 즉, VGG와 ResNet과 같이 사람이 해석이 가능한 특성(interpretibility)을 갖고, 간단한 구조와 general한 특성을 갖고있으며, NAS처럼 자동화된 모델링 과정의 이점을 함께 누리는 것

- 이런 목표를 위해 먼저 VGG, ResNet, ResNetXt와 같은 제약이 적은(uncontrained) 넓은 design space와 같은 구조에서 찾기 시작하였음 이를 AnyNet이라 부름

- 여기에 human-in-the-loop(사람이 실험 진행)을 적용하여 low-dimensional design space를 찾을 이를 regular network라하여 RegNet이라 부름

- 이 RegNet은 various compute regimes(개인 pc, 모바일, 서버 등)과 schedule 길이, network block type에 관계없이 generalize가 됨

- 저자들이 가장 흥미로웠던 점은 이 RegNet이 우리가 지금까지 알고 있던 network의 일반적인 내용들이 맞지 않는단 것을 찾아내었다고 함

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig1.png?raw=true)

## Design Space Design

- general한 모델들을 연구하여 디자인 원칙을 발견하고 이를 모델에 적용하는 것
- 디자인 공간에서 모델을 sampling하고, sampling된 모델의 error distribution을 계산하는 방법으로 metric을 사용
- 즉, 단순한 버전의 initial network(AnyNet)을 입력하여 더 좋거나 단순한 모델을 갖는 design space
- 본 논문에서 제안하는 RegNet은 다음과 같음
  - network 구성의 차원과 유형에서 최대한 단순화
  - 최고 성능 모델들의 higher concentration을 포함
  - 분석 및 해석에 용이

### Tools for Design Space Design

- Design Space를 평가하기 위해 desing space에서 모델을 sampling하고 error distribution result를 characterizing함

- Error distribution을 얻기위해 design space에서 n개의 model을 sampling하여 학습

  > 400M FLOPs와 10epoch을 사용
  >
  > n이 100일때, 모델 모두 학습하는 것은 ResNet-50을 학습하는 것과 같은 FLOPs를 가짐

- Error distribution result를 통해 각각의 design space에서 best model을 추출해 성능을 비교

- 본 논문에서는 design space를 분석하기 위해 emprical distribution function(EDF)를 사용

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/s1.png?raw=true)

> $e_i$: i-th model error
>
> e: error threshold
>
> n: number of model(in design space)

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig2.png?raw=true)

### The AnyNet Design Space

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig3.png?raw=true)

- AnyNet은 stem, body, head로 구성되어 있음

- 본 논문에서는 실제 성능에 영향을 주는 것은 body라고 생각하여 body를 중점으로 body만을 변경하여 계산량과 정확도를 결정하였음

- body는 총 4개의 stage로 구성하였으며 각 stage는 개별적인 block을 갖으며 block 개수($d_i$), block width($w_i$), bottleneck ratio($b_i$), group width($g_i$)를 갖고 있음

  > $d_i$ <= 16
  > $w_i$ <= 1024 중 8로 나누어 떨어지는 수
  >
  > $b_i$ = 1, 2, 4
  >
  > $g_i$=1, 2, 4, 8, 16, 32
  >
  > 목표 FLOPs: 300M~400M

- 본 논문에서는 ResNet에서 사용하는 residual bottleneck block을 사용하였으며, 이를 X block이라고 지칭하고 이를 사용한 네트워크를 AnyNetX라고 함

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig4.png?raw=true)

- AnyNetX design space는 4개의 stage로 이루어져 있으며, 각각의 stage에서는 위에서 언급한 4개의 parameter를 조정함

  > 위에 언급한 조건으로 모델을 탐색하여 $(16 * 128 * 3 * 6)^4=10^{18}$

- 최고 성능 모델을 찾는것이 아닌 general한 design principle을 찾는 것에 집중함
- AnyNetX를 5가지로 나눔

- **AnyNet**$X_A$: 제약이 없는 초기 AnyNetX
- **AnyNet**$X_B$: bottlenet ratio에 대한 조건을 추가($b_i=b$)
- **AnyNet**$X_C$: AnyNet$X_B$에 group width에 대한 조건을 추가. 모든 stage에 대해 group width의 수를 고정$(g_i=g)$

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig5.png?raw=true)

- **AnyNet**$X_D$: AnyNet$X_C$에 block의 width에 제약을 줌
  - $w_{i+1}>=w_{i}$라는 design principle을 발견 함

- **AnyNet**$X_E$: AnyNet$X_D$에 depth에 제약을 줌
  - $d_{i+1}>=d_i$라는 design principle을 발견 함

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig7.png?raw=true)

### The RegNet Design Space

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig8.png?raw=true)

- fig8.의 좌측상단은 $X_E$의 상위20개의 model을 linear하게 표현한 것

- linear한 그래프를 통해 요즘 트렌드에 맞는 width가 커지는 것을 확인할 수 있음

- model의 channel과 depth를 다음 식을 활용하면 linear하게 나타낼 수 있음

  > 그림에서는 48*(j+1)을 사용 
  >
  > 0 <= j <= 20
  >
  > j: block index in stage
  >
  > i: stage index

- 더 간결한 design space를 위해 회색 선들을 quantize할 필요가 있음

- block width에 대해 linear parameterization을 진행

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/s2.png?raw=true)

> $d$: depth
>
> $w_0>0$: initial width
>
> $w_a>0$: slop
>
> $u_j$: channel을 근사화 하는 값

- $u_j$를 quantize하기 위해 $w_m>0$을 도입

  > 이전 stage의 width에서 얼마 만큼 곱해줄지 결정해 줌

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/s3.png?raw=true)

- width per block에서 width per stage로 확장 시키기 위해 아래의 식을 사용

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/s4.png?raw=true)

- 따라서 i-th stage에서 block with $w_i=w_0*w^i_m$으로 표현 가능하며, 하나의 stage의 block의 수는 아래의 식으로 표현이 가능

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/s5.png?raw=true)

- 즉, 네트워크는 $d,w_0,w_a,w_m,b,g$인 6개의 parameter로 결정되며 위의 수식을 통해 block width, block depth가 정해짐
- 이러한 design space를 RegNet이라고 함

> RegNet
>
> d<64
>
> $w_0, w_a<256$
>
> $1.5<=w_m<=3$
>
> b, g: AnyNet과 동일

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig9.png?raw=true)

> $w_m=2$ stage마다 width를 2배 증가
>
> $w_0=w_a$일때가 parameterization을 단순하게 만들어 성능이 향상 되었지만, RegNet의 다양성을 해친다고 생각하여 실제로는 사용하지 않음

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/table1.png?raw=true)

- RegNet이 얼마나 잘 generalization하는지 fig10을 통해 확인할 수 있음

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig10.png?raw=true)

> X: 기본 모델
>
> R: group convolution을 제거한 모델
>
> V: 3*3의 일반적인 convolution block만 있는 모델
>
> VR: V모델에 skip connection을 추가한 모델



## Analyzing the RegNetX Design space

- 일반적인 design pattern
  - 깊은 모델일 수록 성능이 좋다
  - 채널을 두배 늘리는 것이 좋다
  - skip connection이 좋다
  - bottleneck이 좋다

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig11.png?raw=true)

- depth는 약 20개(block-60 layer)의 정도로 크게 변화하지 않아도 best model이 존재
- bottleneck이 1일때(사용하지 않음) best model이 존재
- 채널을 늘릴때 2배 늘리는데 약 2.5배정도를 사용할 때가 best model이 존재

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig12.png?raw=true)

- runtime에 미치는 요인 중 하나인 activation에 대해서도 측정

- runtime에는 flops가 영향을 미친다고 알려져 있지만, 실험 결과 activation이 더 많은 영향을 끼치는 것으로 나타남

  > feature map의 수가 많을 수록 inference time이 증가 -> 메모리에서 움직임이 많을 수록(?)

### RegNetX constrained

- 위의 결과물을 종합하여 저자들은 RegNetX의 design space를 다음과 같이 정의
  - $b=1,d<=40,w_m>=2$
  - parameter수와 activation에 제한

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/fig13.png?raw=true)

## Comparison to Existing Networks

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/regnet/table4.png?raw=true)

- 당시 SOTA model인 efficientnet과 비교하였을때도 더 좋은 성능을 나타냄