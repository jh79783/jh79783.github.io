---
layout: post
title: R-CNN
data: 2021-02-12
excerpt: "R-CNN"
tags: [test]
coments: false
---

IEEE학술지의 CVPR2014에서 공개된 본 논문의 제목은 *Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation*입니다. Ross Girshick 외 4명이 참가하였으며 2021년 2월 기준 약 만6천회 인용되었습니다.

Object Detection에서 가장 좋은 성능을 내는 것은 복잡한 앙상블 모델이었습니다.

하지만 본 논문에서는 VOC 2012 데이터를 사용하여 기존 모델보다 mAP(mean average precision)가 30% 향상되고 간단하고 확장 가능한 detection 알고리즘을 소개하였습니다.

이 알고리즘은 두 가지의 중요한 insight를 갖고있습니다.

1. object를 localize와 segment하기 위한 bottom-up region proposal에 CNN을 적용할 수 있는 것
2. labeled training data가 부족한 경우에 domain-specific fine-tuning을 통한 supervised pre-training을 적용하는 것

저자들은 region proposal과 CNN이 결합하였기 때문에 이러한 알고리즘을 R-CNN이라 명명하였습니다.

## Introduction

지난 10년간 다양한 visual recognition 작업에서는 SIFT와 HOG를 사용하였습니다. 이는 PASCAL VOC object detection에서 일반적으로 사용되는 방법이였습니다.

하지만 back-propagation이 가능한 SGD기반의 CNN이 나타났고, 이것은 PASCAL VOC object detection에서 기존 방법보다 엄청난 성능을 나타나게 되었습니다.

Image Classification과 다르게 object detection에서는 이미지에서의 객체를 localize하는 것이 요구되며, 본 논문의 모델은 sliding window 방법을 사용하였습니다. 또한 높은 해상도를 유지하기 위해 5개의 Convolutional layer를 적용하였습니다.

본 논문에서는 R-CNN의 작동 방식을 다음과 같이 설명하고 있습니다.

1. input 이미지로부터 2000개의 category-independent region proposal을 생성
2. CNN을 사용하여 각 proposal마다 고정된 길이로 feature vector를 추출
3. 각 region마다 category-specific linear SVM을 적용해 classification 수행

> Sliding Window 방법
>
> 물체를 찾기위해 window의 비율을 바꿔가며 모든 영역에 대해 탐색하는 것
>
> 모든 영역을 탐색하는 것은 비효율적이기 때문에 본 논문에서는 Selective search를 사용

## Object detection with R-CNN

본 논문의 모듈은 세가지로 구성되어있습니다.

1. category-independent region proposal을 생성
2. 각 region에 대해서 고정된 길이의 feature vector을 추출하는 convolutional neural network
3. classfication을 위한 linear SVM

### Region proposals

category-independent region proposal을 생성하기 위해 본 논문에서는 selective search를 사용하였습니다.

>Selective search
>
>색상, 질감, 영역크기 등을 이용하여 non-obeject-based segmentation 수행하여 좌측 하단과 같은 small segmented areas를 얻을 수 있음
>
>Bottom-up 방식으로 small segmented areas를 합쳐 더 커다란 segmented areas를 얻음
>
>이를 반복하여 최종적으로 2000개의 region propoasl을 생성
>
>![](.\r-cnn_selective-search.png)

위의 방법을 통해 2000개의 설정한 물체가 있을법한 박스를 추론하게 됩니다.

또한 좀더 정확한 box를 위해 regression을 사용하였습니다.  이를 bounding box regression이라고 하는데, 이를 사용해 mAP가 3~4포인트 정도 높아졌다고 합니다.

### Feature extraction

Selective Search를 통해 나온 region proposal을 CNN을 통과시켜 4096차원의 feature vector를 추출합니다.

이런 feature은 227\*227 RGB이미지의 고정된 크기로 변하며(CNN output 사이즈를 동일하기 만들기 위해), 5개의 conv layer와 2개의 FC layer로 전파됩니다.

### Test-time detection

test image에대해서도 2000개의 region proposal을 추출하였고, 각 proposal에 대해서 이미지 크기를 warp하고 CNN을 통과하였습니다. 이때 추출된 feature vector는 SVM을 사용해 class별로 score를 부여하였는데, intersection-over-union(IoU)를 사용하여 learned threshold보다 높은 score를 갖고있는 selected region에 대해서만 진행하였습니다.

결과적으로 GUP의 경우 이미지당 13초가 걸렸으며 CPU의 경우 이미지당 53초가 걸렸으며, 100k의 linear predictors를 저장하는데 134GB가 필요하였습니다.

### Training

train에 사용되는 모델은 ILSVRC 2012데이터셋으로 미리 학습된 pre-trained모델을 사용하였습니다.

classification에 최적화된 모델을 detection작업과 VOC에 적용하기 위해 region proposals를 통해 SGD방식으로 CNN파라미터들을 업데이트 하였습니다.

추출되는 feature map은 SVM을 통해 classfication 및 bounding regression이 수행됩니다.

> SVM학습을 위해 NMS(non-maximum suppression)와 IoU(intersection-over-union)이라는 개념이 사용됩니다.
>
>IoU는 Area of Overlap(교집합)과 Area of Union(합집합)으로 계산됩니다.
>
>NMS알고리즘은 다음과 같은 순서로 진행됩니다.
>
>1. 예측한 bounding box들의 예측 점수를 내림차순으로 정렬
>2. 높은 점수의 박스부터 나머지 박스들과 IoU계산
>3. IoU값이 지정한 threshold보다 높은 박스를 제거
>4. 더이상 박스가 남지 않을때까지 반복

**softmax대신 SVM을 사용한 이유**

>논문에서 VOC 2007 데이터셋에 softmax와 SVM을 비교해보았습니다.
>
>softmax를 사용하였을경우 54.2%에서 50.9%로 떨어졌다고 합니다.

본 논문에서는 IoU가 0.5이상인 것을 positive라고 보고 활용하였으며, 그 외에는 background라고 두었습니다. 또한 IoU가 0.3미만인 영역을 모두 negative로 두었고 나머지는 모두 무시하였습니다.

> IoU가 0.5~1사이의 영역을 positive로 정의하였음

SGD iteration마다 모든 class의 positive sample 32개와 96개의 background(negative sample), 총 128개의 배치로 학습을 진행하였습니다.

또한 learning rate는 0.001을 사용하였습니다.

### Results on PASCAL VOC2010-12

![](.\r-cnn_table1.png)

이 테이블은 다양한 모델을 VOC2010 데이터셋을 사용한 것을 나타냅니다. 맨 오른쪽에서 mAP를 확인할 수 있습니다.

UVA모델과 R-CNN모델의 mAP를 확인하면 UVA모델을 35.1%, R-CNN모델은 53.7%로 R-CNN모델이 상당히 높은것을 확인할 수 있습니다.

또한 VOC2011, 2012데이터셋에서는 R-CNN BB(Bounding Box regression)은 53.3%의 mAP라는 높은 성능을 내었다고 저자는 말하고 있습니다.

![](.\r-cnn_table2.png)

두번째와 세번째의 결과를 확인하면 fc7의결과가 fc6보다 더 좋지 않게 나온 것을 확인할 수 있습니다.

이는 파라미터가 늘어남에도 불구하고 성능향상에 도움이 되지 않았습니다. 또한  pool5와 fc7의 mAP가 비슷한것을 보면 pool5가 파라미터가 fc7의 6%만을 사용하여 계산되지만 상당히 좋은 결과를 얻을 수 있는 것을 확인할 수 있습니다.

### Conclusion

R-CNN은 데이터가 부족하여도 규모가 커다란 CNN을 학습시킬 수 있는 것을 확인할 수 있었습니다.

하지만 이것은 시간이 매우오래 걸리며 한번에 학습되지 않고, 매우 큰 저장공간이 필요합니다.