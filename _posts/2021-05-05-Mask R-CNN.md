---
layout: post
title: Mask R-CNN
data: 2021-05-05
excerpt: "Mask R-CNN"
tags: [r-cnn, network, segmentation]
coments: false
mathjax: true
---

# Mask R-CNN

- 제목: Mask R-CNN
- 저자: Kaiming He 외 4명(Facebook AI Research)
- 인용수: 약 1.1만회
- 학술지: ICCV 2017

## Mask R-CNN

- Mask R-CNN은 단순히 기존의 Faster R-CNN에서 class, box의 branch에 mask branch를 추가한 것
- 따라서 classification과 box regressor, mask가 출력됨
- 이에 따른 최종 loss공식은 다음과 같음

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_loss.png?raw=true)

- mask의 loss는 binary cross entropy를 사용
- mask branch는 각 RoI에 대해 $Km^2$의 output을 가짐
  - K: class
  - m: feature map(mask) resolution (m\*m)

## Mask Representation

- class, bbox의 정보는 FC를 통해 vector로 변환되어 spatial한 정보가 손실됨

- mask는 conv연산(FCN)을하기때문에 spatial 정보의 손실을 최소화 시킬 수 있음

- FCN을 사용하기 때문에 각각의 RoI에서 mask예측이 가능

- FC보다 더 적은 parameter수로 인해 속도가 증가

- mask를 m\*m의 형태로 만들기 위해서는 RoI의 feature가 요구됨 

  > 정확한 RoI의 spatial 정보 요구

- 이를 위해 본 논문의 핵심인 RoIAlign layer를 개발

## RoIAlign

- RoIPool은 small feature map을 추출하기 위한 작업

  > 다른 크기의 Region proposal이 들어오더라도 pooling을 통해 output의 크기를 똑같이 만들어줌

- 하지만 RoIPool은 RoI feature map을 Quantization을 해주게 됨 

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_quantization.png?raw=true)

- pixel단위로 예측하는 mask는 quantization이 나쁜 영향을 끼치게 됨

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align_problem.png?raw=true)

- 원본 영상의 좌상단 15\*15가 RoI

- CNN을 통해 25\*25의 feature map추출

- 15\*15에 해당하는 feature map에서의 크기는 다음과 같음

  - 128/25=5.12
  - 15/5.12=2.93

- 따라서 feature map에서의 RoI는 2.93\*2.93

- 이런 경우 RoI Pool은 2.93을 반올림하여 3\*3부분을 가져와 예측을 하게됨

  > 예시에서는 0.07이지만, 이 값은 최대 0.5까지 발생하게 되며, 이런 문제를 misalignment라 한다.

- 즉, 실제 RoI와 추출된 feature map사이에서 misalignment가 발생

- 이러한 문제를 해결하기 위해 2.93\*2.93에 해당하는 feature map을 bilinear interpolation을 사용해 보정된 값을 사용

  > interpolation은 채널별로 따로 수행된다.

### RoIAlign에대해 좀더 자세히 알아보자

- 기존의 RoIPooing 방법 

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align1.png?raw=true)

- 3\*3 pooling을 하고 있다고 가정하게 되면 RoI는 다음과 같이 나뉘게 됨

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align2.png?raw=true)

- 하나의 grid에 6개의 다른 데이터 값이 들어있기 때문에 sampling을 통해 데이터를 얻게됨
- sampling을 위해서는 하나의 grid에 4개의 sampling point를 만듬

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align3.png?raw=true)

- 위의 sampling point에 대해서 하나하나씩 bilinear interpolation을 적용

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align4.png?raw=true)

- 추출된 sample points에 대해 max pooling 적용하여 3\*3 pooling

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align5.png?raw=true)

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_align6.png?raw=true)

## Network Architecture

- BackBone
  - 이미지의 feature를 추출하기 위해 사용
  - ResNet과 FPN을 사용하였음
  - C4라고 부르는 4번째 stage의 최종 conv layer에서 feature를 추출하였음
- Head
  - Classfication과 Regression의 Mask Prediction을 위해 사용
  - 기존의 classifcation과 regression에 mask branch를 추가

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_figure3.png?raw=true)

- 왼쪽: ResNet backbone
- 오른쪽: FPN backbone



## Implementation Details

- training
  - Loss mask는 positive RoI에 의해서만 정의됨
    - Positive RoI: GT와 IoU가 0.5이상
  - image-centric training방식을 채택하였기 때문에 image를 800pixel로 resize해줌
  - GPU당 2개의 mini-batch
  - 이미지는 sampling된 N개의 RoI가 있으며, positive:negative = 1:3
    - ResNet: N=64
    - FPN: N=512
  - 총 GPU: 8개
  - 총 학습 횟수: 160,000
  - 학습률: 0.02

## Inference

- ResNet의 proposal: 300
- FPN의 proposal: 1000
- mask branch는 score가 높은 상위 100개에 대해 NMS 적용

## Experiments

- COCO dataset을 사용하여 성능 측정

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_table1.png?raw=true)

- Mask R-CNN은 기존의 SOTA보다 더 좋은 성능을 나타내었음

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_figure5.png?raw=true)

- COCO 2016 segmentation challenges우승한 FCIS와 비교하였을때 Mask R-CNN이 더 뛰어난 성능을 보여줌

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_result_c.png?raw=true)

- RoIAlign을 사용함으로써 더 높은 성능을 나타냄

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/maskrcnn/maskrcnn_table3.png?raw=true)

- Box detection도 더 좋은 결과를 나타냄