---
layout: post
title: SSD
data: 2021-04-04
excerpt: "SSD"
tags: [SSD, detector]
coments: false
mathjax: true
---

# SSD

- 제목: SSD: Single Shot Multibox Detector
- 학회: ECCV 16
- 인용 수: 약1.3만회

## Introduction

이 때의 sota는 Faster R-CNN이였습니다.

Faster R-CNN은 region proposal을 통해 검출하는 방식이였기 때문에 연산량이 많으며 속도는 7FPS를 나타내었습니다. 

속도를 향상시키고자 Faster R-CNN에 많은 시도를 하였지만, 속도가 빨라진 만큼 정확도가 떨어지는 현상이 나타났습니다.

본 논문에서는 region proposal을 사용하지 않으며 속도도 빠르며 정확도도 높은 SDD를 제안합니다.

> VOC2007 데이터 사용
>
> SSD: 59FPS, 74.3%
>
> Faster R-CNN: 7FPS, 73.2%
>
> YOLO: 45FPS, 63.4%

region proposal을 사용하지 않으며 정확도를 올리기 위해 다양한 scale과 aspect ratio를 갖는 default box를 사용하였습니다.

## SSD

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_fig1.png?raw=true)

SSD의 framework입니다.

ssd는 input으로 image와 gt boxes을 받아 train을 진행하게 됩니다.

convolutional에서 evaluate할 때는 다른 크기의 feature map의 위치에서 다양한 비율의 default box set을 사용하게 됩니다. 이때, default box에서 shape offset과 모든 object category에 대한 confidence를 예측하게 됩니다.

### Model

SSD는 feed-forward convolutional network에 기반한 접근 방식을 사용합니다.

이때의 network는 NMS를 거친 후 최종적으로 bbox와 score를 포함한 box를 포함한 network입니다.

그 후 network에 auxiliaray structure를 추가하여 다음과같은 기능을 통해 detection을 하게 됩니다.

1. **Multi-scale feature maps for detection**

base network에서 끝이 잘린 convolutional feature layer를 추가하였습니다.

이런 layer는 size가 점점 줄어들고 다양한 scale에서 예측이 가능할 수 있습니다.

> 즉, 일반적으로 끝 layer는 fc layer인데, 이것을 conv layer로 변경한 후 auxiliaray structure와 연결 했다는 것
>
> fc layer가 제거되면서 detection 속도가 향상됨.
>
> YOLOv1의 경우 단일 scale의 feature map을 사용하여 다양한 크기의 객체를 포착하는 것이 어렵다는 점이 있었음.
>
> 이런 문제를 해결하기 위해 network의 중간에 있는 conv layer의 feature map을 추출해 사용하는 방법을 제안하였음

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_arch.png?raw=true)

base network에서 하나의 feature map을 추출하고 base에서 auxiliary로 연결해주는 곳에서 한가지 더, auxiliary에서 추가적으로 추출하여 총 6개의 feature map을 얻을 수 있습니다.

2. **Convolutional predictors for detection**

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_fig2.png?raw=true)

fig. 2에서 윗쪽을 보게 되면 conv layer에서 3\*3\*p의 conv layer를 추가로 통과시킨 것을 볼 수 있습니다.

이것은 m\*n\*p의 feature layer를 얻기위한 것으로, m\*n의 위치에 3\*3\*p의 kernel을 적용시킨 것입니다.

이것을 detection에 사용하며, default box에 대응되는 offset을 구하여 bbox를 예측할 수 있습니다.

3. **Default boxes and aspect ratios**

각 feature map cell에서 default bounding box를 만들게 됩니다.

그리고 이 default box와 대응되는 곳에서 predict box의 offset(좌표)과 per-class score를 예측합니다.

따라서 (c+4)\*k의 filter가 필요하게 됩니다.

최종적으로 feature map cell은 feature map이 m\*n 이라면 m\*n(c+4)\*k의 파라미터를 갖게 됩니다.

> k: box의 갯수
>
> c: score 갯수

### Training

SSD는 이 당시의 모델들과 비교하였을때, 위치가 정확한 dataset이 필요하였기 때문에 다음과 같은 방법들을 사용하여 train하였습니다.

1. Matching strategy

training시에 default box가 GT box에 해당하는지 확인해야 합니다. 따라서 각 GT에 대해 default box로부터 다양한 위치, 크기, 비율을 선택합니다.

선택하기 위해 MultiBox가 사용한 것처럼 jaccard overlap을 통해 가장 높은 점수를 갖는 GT box와 default box에 대해 매칭 시켰습니다.

> https://ko.wikipedia.org/wiki/%EC%9E%90%EC%B9%B4%EB%93%9C_%EC%A7%80%EC%88%98

또한 threshold값을 0.5보다 높게 설정함으로 써 더 많이 겹치는 상자에 대해 수행하도록 하였습니다.

2. Training objective

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_s1.png?raw=true)

사용한 전체 loss function은 위와 같습니다.

localization loss와 confidence loss를 합친 공식입니다.

또한 위의 공식은 다음과 같은 식으로 정리가 됩니다.

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_s2.png?raw=true)

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_s3.png?raw=true)

> i: default box의 index
>
> j: GT box의 index
>
> p: object의 index
>
> N: GT box와 매칭된 default box의 갯수 (N이 0이면 loss가 0)
>
> l: 예측한 box
>
> g: gt box
>
> d: default box
>
> c: confidence score
>
> cx, cy: default bbox의 중심좌표
>
> w, h: default bbox의 너비와 높이
>
> $\alpha$: weight term으로 cross validation에서 1로 설정됨
>
> $\hat{g}$: gt box와 default box의 gap
>
> > $\hat{g}$의 값들은 default box를 통해 normalize가 되었다.(?)
> >
> > posivie class에 대해 softmax를 진행
>
> Lconf은 기본적으로 cross entrophy공식이며, 앞의 공식은 i번째 default box가 p클래스의 j번째 gt box와 match되는 것에 대한 loss를 계산한다는 것이고 앞의 공식은 물체가 없다고 예측하였지만 gt box가 있는 경우에 대한 loss를 계산해줌

3. Choosing scales and aspect ratios for default boxes

다양한 feature map을 사용하기 때문에 이러한 feature map에 대한 scale와 ratio를 default box에 대해 생성하기 위해 다음과 같은 공식을 사용하였습니다.

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_s4.png?raw=true)

> m: feature map의 갯수
>
> s: default box의 크기
>
> min: 가장 낮은 차원의 feature map크기, 0.2사용
>
> max: 가장 높은 차원의 feature map크기, 0.9사용
>
> aspect ratio: 1, 2, 3, 1/2, 1/3 을 설정하여 사용

결과적으로 한개의 cell당 6개의 default box가 생겨났습니다.

따라서 총 박스의 갯수는 m\*n\*6(c+1)개의 default box가 생성됩니다.

4. Hard negative mining

matching 후, 대부분의 default box는 negative상태인데, 이것은 데이터의 불균형을 초래하기 때문에 마지막 class loss에서 모든 데이터를 사용하는 것이 아닌 negative:posivie = 3:1로 사용하게 됩니다.

저자들은 위와 같은 비율을 사용하였을때 가장 optimal하다고 말하고 있습니다.

5. data augmentation

다양한 형태의 object가 필요하기 때문에 0.1, 0.3, 0.5, 0.7 or 0.9의 jaccard overlap을 사용하였으며 무작위로 sampling 하여 patch를 선택하였습니다.

각 sample은 기존 이미지에서 0.1~1배의 크기를 갖게 되며, 비율 또한 2배 or 1/2배를 합니다.

sampling작업이 종료되면, 원래의 크기로 resize한 후, 50%의 확률로 filp하여 적용하게 됩니다.

## Experimental Results

base network는 VGG16을 사용하였습니다.

하지만 그대로 사용한 것이 아닌 위에서 언급한 것처럼 layer의 마지막 부분을 변형시켜 적용하였습니다.

fine-tune을 한 모델에서는 SGD를 사용하였고, 초기 learning rate로는 $10^{-3}$, batch size는 32를 사용하였습니다.

PASCAL VOC2007 data를 사용하였을때 다음과 같은 결과가 나타났습니다.

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_table1.png?raw=true)

table1의 아랫쪽을 보면 SSD300과 SSD512가 있는데 이는 해상도를 다르게 한 결과입니다.

결과를 보면 해상도가 커질수록 성능이 좋게 나오는 것을 확인할 수 있습니다.

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/ssd/ssd_table2.png?raw=true)

또한 data augmentation을 사용한 것을 비교한 결과인데 사용하였을 때 약 8.8% mAP가 향상된 것이 확인 되었습니다.

# Conclusion

1 stage detector로써 여러 차원의 feature map으로 부터 다양한 크기의 bbox를 가져오는 것이 핵심인 모델입니다.

이것이 효과가 있었으며 성능향상에 도움이 되는 것을 확인하였으며, yolov1, faster rcnn과 비교하였을때 높은 인식률과 속도를 나타내었습니다.+