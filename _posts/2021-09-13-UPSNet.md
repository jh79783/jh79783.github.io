---
layout: post
title: UPSNet
data: 2021-09-13
excerpt: "UPSNet"
tags: [segmentation]
coments: false
mathjax: true
---

# UPSNet

- 제목: UPSNet: A Unified Panoptic Segmentation Network
- 저자: Yuwen Xiong, Renjie Liao 외 5명 (Uber)
- 인용수: 168회
- 학술지: CVPR2019



## Introduction

- Semantic segmentation과 Instance segmentation은 이미지를 픽셀 단위로 다루는 것을 목표로 함

- 하지만 sementic과 instance의 모델은 다른 형태의 모델을 사용하였음

- 따라서 두 개념을 합친 panoptic segmentation이 고안되었고, 본 논문에서는 이를 위한 모델을 제안함

- UPSNet은 하나의 network를 backbone으로 사용하였으며, sementic과 instance head를 설계하였음

- sementic head는 deformable convolution을 사용하였으며, instance head는 FPN을 사용하여 설계함

- 또한 instance head는 Mask R-CNN의 구조를 따르기 때문에 mask segmentation, bounding box, class를 출력함

- 가장 중요한 것은 두 head를 병합할 panoptic head를 설계함

- panoptic head는 최종적으로 panoptic segmentation을 예측하는 역할을 수행하며, 앞선 두 head의 semantic logit과 mask logit에 unknown class를 추가하기도 함

  > unknown class를 추가함으로 써 두 head의 결과물들의 conflict를 해결할 수 있다.

- panoptic head는 매우 가볍기 때문에 다양한 backbone에도 쉽게 적용이 가능하며, 이를 통해서 end-to-end로 학습이 가능함

- 성능을 위해 cityscapes와 COCO, cityscapes와 유사한 자체 데이터를 사용하였으며, 그 결과 sota를 달성 및 inference속도도 훨씬 빠른 결과를 얻어냄

## Unified Panoptic Sementation Network

### UPSNet Architecture

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/fig1.png?raw=true)



- Backbone은 Mask R-CNN의 backbone인 ResNet에 FPN을 적용한 것을 backbone으로 사용함

#### Instance Segmentation Head

- bounding box regression, classification, segmentation mask를 출력하는 Mask R-CNN을 사용
- 해당 head에서 *thing* class로 명확하게 하는 representation을 생성함
- 생성된 representation이 panoptic head에 들어가 각 instance에 logit에 영향을 줌

#### Semantic Segmentation Head

- 해당 head에서는 instance와는 무관하게 모든 semantic class를 segment를 목표로 함
- FPN에서 얻은 multi scale feature(2, 3, 4, 5)를 input으로 받아 deformable convolution을 기반으로한 sub network로 구성되어 있음
- multi scale feature를 deformable convolution network에 통과시킨 후 upsample하여 multi scale feature를 동일한 크기로 조정해준 후 concatenate해 줌
- concatenate를 한 feature를 1\*1 convolution을 진행하여 최종적으로 softmax를 통과해 semantic class를 출력하게 됨

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/fig2.png?raw=true)

- 기본적으로 loss는 pixel-wise cross entropy loss를 사용함

- 거기에 추가적으로 foreground(thing)를 더 강조하기 위하여 RoI loss를 추가함

- RoI loss는 1\*1 convolution 후에 나온 logit map을 gt의 bbox로 crop하고 28\*28로 resize한 patch에 cross entropy를 적용한 loss

  > 해당하는 patch에 더 많은 패널티를 주기 위해서

- 후의 추가적인 연구에서는 RoI loss를 사용한 것이 더 좋은 성능을 나타내었음

### Panoptic Segmentation Head

- 앞선 semantic / instance head의 결과를 해당 head에서 합치는 역할을 수행하여 Z라는 Panoptic logit을 만들어 각 픽셀마다 class와 instance를 결정하는 것

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/fig3.png?raw=true)

> X: semantic head의 logit map
>
> Y: instance head의 logit map
>
> N: class 수

- instance segmentation에서는 instance의 logit Y, box B, class_ID C가 출력됨

- stuff를 분류하기위해 $X_{stuff}$를 Z의 $N_{stuff}$의 첫번째 channel에 할당함
- $X_{thing}$에서 instance head의 B값을 이용하여 B안에 있는 값만을 사용해 $X_{mask}$를 얻어냄
- $Y_{mask}$는 instance head의 mask를 $X_{mask}$와 같은 크기로 만든 것을 의미함
- 따라서 $X_{mask}$와 $Y_{mask}$를 통해 instance를 할당할 수 있음
- Z의 instance channel을 모두 채우면, softmax를 취해 pixel-wise class를 예측함
- 이때, 최대 값이 $N_{stuff}$에 속한다면 해당 픽셀은 stuff class에 속하게 되며, 그렇지 않으면 instance ID에 속함
- stuff class와 instance ID가 정해지면 이후 pixel-wise cross entropy를 통하여 loss를 계산함

> instance의 class와 stuff의 class가 동일한 빈도수일때 conflict가 발생할 수가 있기 때문에 이 경우, instance class를 사용한다.



- PQ metric을 보면 FN/FP가 증가하면 성능이 떨어지게 되며 됨

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/s1.png?raw=true)

- FP가 하나 증가하게 되면 FN이 자연스럽게 증가하게 됨

  > 사람을 자전거라고 예측한경우 사람 class에 대한 FN이 증가하며, 자전거 class에 대해서는 FP가 증가

- 이것이 thing에 만 한정된것이 아닌 stuff에 까지도 영향이 줄 수 있다고 생각하였음

- 따라서 이런 경우 unknown이라 예측한다면 해당 class의 FN을 증가시키지만 다른 class의 FP는 증가되지 않을 수 있음

- 그래서 저자들은 unknown class를 다음과 같이 정의함

$$
Z_{unknown}=max(X_{thing})-max(X_{mask})
$$

- 특정 픽셀값에 대한 $X_{thing}$의 최대값이 $X_{mask}$보다 클 경우 FN일 가능성이 크다고 보았음

- 또한 Unknown class의 GT를 만들기 위해 학습 과정에서 30%의 확률로 GT mask를 Unknown으로 설정함

  > metric 과정에서 unknown에 대한 픽셀은 계산되지 않음

### Implementation Details

- 학습 과정에는 GT의 데이터를 이용하지만, inference 과정에서는 Mask R-CNN의 결과를 토대로 panoptic logit tensor를 생성함
- 이때 Mask pruning을 통해 instance의 class 개수를 설정함
- Mask pruning이란 panoptic logit에 instance head에서 얻은 mask중 어떤 mask를 사용할지 결정하는 것
- IoU를 0.5로 설정하여 NMS를 진행하고 나온 box에 대해 class prob가 0.6이상인 box만 남김
- 그 후 각 class에 대해 image와 동일한 mask를 생성하고, 내림차순으로 정렬함
- 이전의 mask와 현재 생성할 mask의 IoU가 0.3이하인 경우에 겹치지 않는 부분에 mask를 생성함

### Experiments

- COCO, Cityscapes, Uber내부 dataset을 사용하여 실험을 진행함
- COCO dataset의 결과

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/table2.png?raw=true)

- Cityscapes dataset의 결과

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/table3.png?raw=true)

- 본 모델을 사용하여 inference시에 최대 3배가 넘는 속도 향상이 있었음

  > 하나의 GTX 1080 TI를 사용하였다.

  

![](C:\workspace\논문\upsnet\table5.png)

![](https://github.com/jh79783/jh79783.github.io/blob/main/assets/img/upsnet/fig4.png?raw=true)